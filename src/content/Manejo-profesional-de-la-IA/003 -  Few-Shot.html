
    <div class="relative overflow-hidden">
        <!-- Background decorative elements for dynamic aesthetic -->
        <div class="absolute top-0 left-0 w-80 h-80 bg-accent-purple rounded-full mix-blend-multiply filter blur-xl opacity-20 animate-spin-slow" style="animation-delay: -2s;"></div>
        <div class="absolute bottom-0 right-0 w-96 h-96 bg-accent-gold rounded-full mix-blend-multiply filter blur-xl opacity-20 animate-spin-slow"></div>

        <!-- Header -->
        <header class="relative pt-12 pb-16 text-center max-w-4xl mx-auto px-4 z-20">
            <div class="relative z-10 flex flex-col items-center">
                <!-- Title -->
                <h1 class="font-display text-4xl md:text-6xl text-primary-text mb-4 leading-tight tracking-tight animate-fade-in-up">
                    Aprendizaje por Ejemplos: Dominando la Técnica Few-Shot en la Interacción con Modelos de Lenguaje
                </h1>
                <!-- Subtitle -->
                <div class="flex flex-col items-center gap-4 mt-4 animate-fade-in-up" style="animation-delay: 0.2s;">
                    <span class="text-base font-body text-secondary-text italic">Una Guía Detallada para la Interacción Efectiva con LLMs</span>
                    <div class="w-12 h-0.5 bg-gradient-to-r from-transparent via-accent-gold to-transparent rounded-full animate-grow-width"></div>
                </div>
            </div>
        </header>

        <article class="max-w-3xl mx-auto px-6 pb-20 z-20 relative">
            <!-- Introducción -->
            <p class="text-base md:text-lg leading-relaxed text-secondary-text text-center mb-16 animate-fade-in-up" style="animation-delay: 0.4s;">
                Al finalizar este capítulo, el estudiante comprenderá y será capaz de aplicar la técnica <strong>Few-Shot Prompting</strong> para guiar de manera efectiva a los Modelos de Lenguaje Grandes (LLM), optimizando su rendimiento en tareas complejas y específicas sin la necesidad de un reentrenamiento exhaustivo.
            </p>

            <!-- Image 1 -->
            <figure class="group w-full mb-16 relative rounded-xl overflow-hidden shadow-xl hover:shadow-2xl hover:-translate-y-1 transition-all duration-300 ease-in-out animate-fade-in-up" style="animation-delay: 0.6s;">
                <div class="bg-bg-subtle aspect-video md:aspect-[21/9] flex items-center justify-center overflow-hidden">
                    <img src="https://placehold.co/600x400?text=Introduccion+Few-Shot+Prompting" alt="Ilustración conceptual de la técnica Few-Shot Prompting, mostrando un modelo de lenguaje recibiendo instrucciones con ejemplos." class="h-full w-full object-cover object-center transform transition-transform duration-500 ease-out group-hover:scale-105">
                </div>
                <figcaption class="absolute bottom-0 left-0 right-0 bg-gradient-to-t from-bg-dark/80 to-transparent p-4 text-secondary-text text-xs text-right opacity-0 group-hover:opacity-100 transition-opacity duration-300">
                    Ilustración: Few-Shot Prompting
                </figcaption>
            </figure>

            <!-- Body text container -->
            <div class="space-y-7 text-sm md:text-base leading-relaxed text-secondary-text mb-12">
                <p>
                    <strong>Objetivo de Aprendizaje</strong><br>
                    Al finalizar este capítulo, el estudiante comprenderá y será capaz de aplicar la técnica <strong>Few-Shot Prompting</strong> para guiar de manera efectiva a los Modelos de Lenguaje Grandes (LLM), optimizando su rendimiento en tareas complejas y específicas sin la necesidad de un reentrenamiento exhaustivo.
                </p>
                <p>
                    <strong>Definición y Relevancia</strong><br>
                    La interacción con la inteligencia artificial generativa ha evolucionado rápidamente, pasando de instrucciones básicas a métodos más sofisticados que permiten una guía más precisa. Dentro de este panorama, emerge la <strong>técnica Few-Shot Prompting</strong> como un pilar fundamental en el procesamiento del lenguaje natural (NLP). En esencia, esta técnica dota a un modelo de lenguaje con un reducido número de ejemplos de pares entrada-salida directamente dentro de la instrucción o <em>prompt</em> que se le proporciona. Su relevancia radica en la capacidad de permitir que el modelo infiera patrones, estructuras y el formato de salida deseado para una nueva tarea no vista previamente, todo ello sin la exigencia de una extensa sintonización fina o un reentrenamiento completo.
                </p>
                <p>
                    <strong>Antecedentes</strong><br>
                    Antes de la consolidación de técnicas como Few-Shot, la interacción con los LLM a menudo dependía de la <strong>Zero-Shot Prompting</strong>, donde el modelo debía ejecutar una tarea basándose únicamente en su conocimiento preentrenado y una descripción de la tarea, sin ejemplos. Si bien efectiva para tareas sencillas, las complejidades de ciertas aplicaciones demandaban una guía más explícita. La técnica Few-Shot llena este vacío, aprovechando la vasta capacidad de los LLM para generalizar a partir de información limitada, simulando un tipo de aprendizaje más cercano al humano.
                </p>
                <p>
                    Para comprender la <strong>Few-Shot Prompting</strong>, imaginemos a un ser humano aprendiendo una nueva habilidad. Si le pedimos a alguien que clasifique diferentes tipos de frutas en "dulces" o "ácidas", y solo le decimos la regla, quizás cometa errores iniciales. Pero si le mostramos un par de ejemplos –"manzana: dulce", "limón: ácido", "plátano: dulce"–, la persona rápidamente aprenderá a identificar el patrón y aplicarlo a una nueva fruta como "naranja". Los Modelos de Lenguaje Grandes operan de una manera análoga cuando se les aplica la técnica Few-Shot.
                </p>
                <!-- Image 2 -->
                <figure class="group w-full mb-16 relative rounded-xl overflow-hidden shadow-xl hover:shadow-2xl hover:-translate-y-1 transition-all duration-300 ease-in-out animate-fade-in-up" style="animation-delay: 0.8s;">
                    <div class="bg-bg-subtle aspect-video md:aspect-[21/9] flex items-center justify-center overflow-hidden">
                        <img src="https://placehold.co/600x400?text=Analogia+Aprendizaje+Humano" alt="Ilustración comparando el aprendizaje humano con ejemplos y la técnica Few-Shot en LLMs." class="h-full w-full object-cover object-center transform transition-transform duration-500 ease-out group-hover:scale-105">
                    </div>
                    <figcaption class="absolute bottom-0 left-0 right-0 bg-gradient-to-t from-bg-dark/80 to-transparent p-4 text-secondary-text text-xs text-right opacity-0 group-hover:opacity-100 transition-opacity duration-300">
                        Ilustración: Analogía de Aprendizaje
                    </figcaption>
                </figure>
                <div class="border-l-4 border-accent-gold pl-6 py-4 bg-bg-subtle/50 rounded-r-lg shadow-inner">
                    <p class="text-primary-text italic text-lg">
                        <strong class="text-accent-gold">Insight Clave:</strong> La <strong>Few-Shot Prompting</strong> no modifica los parámetros internos del modelo, sino que <em>aprovecha su conocimiento preentrenado</em> para interpretar el contexto y el patrón deseado a partir de los ejemplos provistos en el <em>prompt</em>.
                    </p>
                </div>
                <p>
                    El proceso lógico detrás de la Few-Shot Prompting se desglosa en varios pasos:
                </p>
                <!-- Ordered List -->
                <ol class="list-decimal list-inside space-y-3 pl-4 text-secondary-text">
                    <li class="pl-2"><strong class="text-primary-text">Consulta del Usuario:</strong> Se formula una petición inicial al LLM.</li>
                    <li class="pl-2"><strong class="text-primary-text">Ejemplos en el Prompt:</strong> Varios ejemplos de la tarea deseada, presentados como pares de entrada y salida, se incluyen directamente en el <em>prompt</em> junto con la nueva consulta. Típicamente, este número de ejemplos oscila entre 2 y 10, aunque puede variar según la complejidad de la tarea.</li>
                    <li class="pl-2"><strong class="text-primary-text">Reconocimiento de Patrones:</strong> El LLM procesa el <em>prompt</em> en su totalidad. Utiliza los ejemplos para identificar el patrón subyacente, el contexto y el estilo de respuesta esperado. Es crucial entender que el modelo no está "aprendiendo" en el sentido tradicional de ajustar sus pesos, sino que está detectando la <em>intención</em> y la <em>estructura</em> implícita en la secuencia de ejemplos.</li>
                    <li class="pl-2"><strong class="text-primary-text">Generación de Salida:</strong> Una vez que el patrón es reconocido, el modelo aplica esta comprensión para generar una salida para la nueva consulta que se alinea con los ejemplos proporcionados.</li>
                </ol>
                <p>
                    Esta mecánica ofrece ventajas significativas. Primero, una notable <strong>eficiencia y flexibilidad</strong>, ya que reduce drásticamente la necesidad de grandes conjuntos de datos etiquetados y entrenamientos extensos. Esto permite capitalizar rápidamente los modelos preentrenados. Segundo, una <strong>mejora en la precisión</strong>; al ofrecer múltiples ejemplos, el modelo adquiere una comprensión más profunda de tareas complejas, resultando en una mayor exactitud y consistencia en comparación con métodos <strong>Zero-Shot</strong> o <strong>One-Shot</strong>. Finalmente, su <strong>versatilidad</strong> es inmensa, siendo aplicable a una vasta gama de tareas como la clasificación, la sumarización o la generación de resultados estructurados, sin necesidad de reentrenamiento para cada nueva tarea.
                </p>

                <!-- Section Title 2 -->
                <h3 class="font-display text-3xl text-primary-text mb-4 mt-12 pt-8 border-t border-border-subtle">Técnicas Avanzadas y Aplicación</h3>
                <p>
                    La implementación de la Few-Shot Prompting profundiza en la capacidad de los LLM para imitar el aprendizaje humano a partir de la experiencia. Bajo el capó, el "porqué" funciona reside en la arquitectura masiva de los transformadores que sustentan a los LLM, los cuales han sido preentrenados con cantidades ingentes de texto. Esta fase de preentrenamiento les confiere una capacidad intrínseca para identificar relaciones semánticas y sintácticas complejas. El "cómo" se ejecuta es a través de la cuidadosa selección e inclusión de los ejemplos en el <em>prompt</em>, que actúan como "pistas contextuales" que dirigen la atención del modelo hacia el subconjunto de su vasto conocimiento más relevante para la tarea en cuestión.
                </p>
                <!-- Image 3 -->
                <figure class="group w-full mb-16 relative rounded-xl overflow-hidden shadow-xl hover:shadow-2xl hover:-translate-y-1 transition-all duration-300 ease-in-out animate-fade-in-up" style="animation-delay: 1s;">
                    <div class="bg-bg-subtle aspect-video md:aspect-[21/9] flex items-center justify-center overflow-hidden">
                        <img src="https://placehold.co/600x400?text=Arquitectura+Transformer+LLM" alt="Diagrama simplificado de la arquitectura Transformer de un LLM." class="h-full w-full object-cover object-center transform transition-transform duration-500 ease-out group-hover:scale-105">
                    </div>
                    <figcaption class="absolute bottom-0 left-0 right-0 bg-gradient-to-t from-bg-dark/80 to-transparent p-4 text-secondary-text text-xs text-right opacity-0 group-hover:opacity-100 transition-opacity duration-300">
                        Ilustración: Arquitectura LLM
                    </figcaption>
                </figure>
                <p>
                    A pesar de sus bondades, la técnica Few-Shot no está exenta de limitaciones. Una de las más críticas es el <strong>tamaño de la ventana de contexto</strong> del modelo, que determina la cantidad de texto que el LLM puede procesar en una sola interacción. Esto limita directamente el número de ejemplos que pueden ser incluidos en el <em>prompt</em>. Otra consideración fundamental es la <strong>selección de ejemplos</strong>: la calidad y la pertinencia de los ejemplos proporcionados son cruciales, ya que ejemplos mal elegidos pueden llevar a un rendimiento subóptimo del modelo. Además, existe un <strong>potencial de sesgo</strong>: cualquier sesgo inherente en los ejemplos puede ser aprendido y, por consiguiente, propagado por el modelo en sus respuestas.
                </p>
                <p>
                    Para situar la Few-Shot Prompting en perspectiva, es útil compararla con otras técnicas:
                </p>
                <ul class="list-disc list-inside text-secondary-text space-y-3 pl-4">
                    <li class="pl-2"><strong class="text-primary-text">Zero-Shot Prompting:</strong> El modelo recibe solo una descripción de la tarea, sin ejemplos. Confía enteramente en su conocimiento preentrenado. Es óptima para tareas rápidas donde el modelo debería entender la solicitud sin guía adicional.</li>
                    <li class="pl-2"><strong class="text-primary-text">One-Shot Prompting:</strong> Se proporciona un único ejemplo para aclarar la tarea o el formato deseado. Es útil cuando se necesita una guía más específica que Zero-Shot, o cuando el modelo puede lidiar con ambigüedad.</li>
                    <li class="pl-2">La Few-Shot Prompting se posiciona como un punto intermedio potente, ofreciendo más guía que las anteriores para una comprensión más robusta.</li>
                </ul>

                <h3 class="font-display text-3xl text-primary-text mb-4 mt-12 pt-8 border-t border-border-subtle">Escenarios de Aplicación</h3>
                <p>
                    La utilidad de la Few-Shot Prompting se manifiesta especialmente en tareas complejas que demandan una variedad de entradas, requieren un formato preciso o exigen un alto grado de precisión.
                </p>
                <p>
                    <strong>Análisis de Sentimiento:</strong> Los modelos pueden clasificar el sentimiento de un texto (positivo, negativo, neutro) con datos etiquetados limitados, si se les proporcionan unos pocos ejemplos de cómo se han clasificado previamente textos similares. Por ejemplo, <code class="bg-bg-subtle px-1 rounded">Input: "Excelente servicio." -> Output: Positivo. Input: "Retraso inaceptable." -> Output: Negativo. Input: "El producto llegó." -> Output: Neutro.</code>
                </p>
                <p>
                    <strong>Reconocimiento de Acciones en Videos:</strong> Aunque la investigación base no profundiza, esta aplicación sugiere cómo el modelo podría aprender a identificar patrones de comportamiento a partir de un puñado de descripciones o transcripciones de acciones específicas.
                </p>
                <p>
                    <strong>Generación de Salida Estructurada:</strong> Para extraer información específica o reformatear datos, los ejemplos pueden mostrar al LLM exactamente cómo se espera la salida (ej., convertir texto libre en formato JSON).
                </p>

                <h3 class="font-display text-3xl text-primary-text mb-4 mt-12 pt-8 border-t border-border-subtle">Técnicas Avanzadas Adicionales</h3>
                <p>
                    La Few-Shot Prompting puede combinarse y complementarse con otras estrategias para potenciar aún más la interacción con los LLM:
                </p>
                <ul class="list-disc list-inside text-secondary-text space-y-3 pl-4">
                    <li class="pl-2"><strong class="text-primary-text">Chain-of-Thought (CoT) Prompting:</strong> Esta técnica anima al modelo a generar pasos de razonamiento intermedios antes de ofrecer la respuesta final. Al integrar CoT con Few-Shot, los ejemplos no solo muestran la entrada y la salida, sino también el <em>proceso de pensamiento</em> que lleva a esa salida, mejorando la coherencia y la lógica del resultado.</li>
                    <li class="pl-2"><strong class="text-primary-text">Ejecución de Tareas Multi-Paso:</strong> Para tareas que inherentemente requieren múltiples etapas, dividir el <em>prompt</em> en partes más pequeñas y manejables, cada una con sus propios ejemplos Few-Shot, puede ser muy efectivo.</li>
                    <li class="pl-2"><strong class="text-primary-text">Juego de Roles y Comprensión Contextual:</strong> Proporcionar al modelo un rol específico (ej., "Eres un experto en <em>marketing</em>") o una información contextual más profunda puede refinar aún más su producción, guiándolo a adoptar un estilo o una perspectiva particular, incluso en los ejemplos Few-Shot.</li>
                </ul>

                <!-- Important Text Callout -->
                <div class="my-16 text-center animate-fade-in-up" style="animation-delay: 1.2s;">
                    <p class="font-display text-xl md:text-3xl text-primary-text leading-normal mb-4 border-l-4 border-accent-gold pl-6 py-4 bg-bg-subtle/50 rounded-r-lg shadow-inner">
                       La Few-Shot Prompting representa más que una simple técnica; es un paradigma de cómo podemos enseñar a las máquinas a generalizar a partir de la experiencia, emulando la cognición humana de una manera eficiente y escalable.
                    </p>
                </div>

                <div class="h-0.5 bg-gradient-to-r from-transparent via-border-subtle to-transparent rounded-full my-12"></div>
            </div>
        </article>

        <article class="max-w-3xl mx-auto px-6 pb-20 z-20 relative">
            <h2 class="font-display text-4xl text-primary-text mb-8 mt-20 text-center animate-fade-in-up" style="animation-delay: 1.4s;">Ejemplos Prácticos</h2>

            <!-- Example 1: La Receta del Chef Aprendiz -->
            <div class="group bg-bg-subtle p-8 rounded-xl shadow-xl border border-border-subtle hover:shadow-2xl hover:border-accent-purple/50 hover:-translate-y-1 transition-all duration-300 ease-in-out mb-12 animate-fade-in-up" style="animation-delay: 1.6s;">
                <h3 class="font-display text-2xl text-primary-text mb-3">La Receta del Chef Aprendiz</h3>
                <p class="text-sm text-secondary-text mb-4"><strong>Nivel:</strong> Analogía</p>
                <blockquote class="border-l-4 border-accent-gold pl-4 italic text-secondary-text mb-6 bg-bg-dark/50 py-3 rounded-r-md">
                    <strong class="text-primary-text">Concepto Clave:</strong> Proporcionar al modelo un pequeño número de ejemplos de entrada-salida dentro del prompt para guiar su rendimiento en una tarea nueva y no vista.
                </blockquote>
                <p class="mb-4 text-sm md:text-base leading-relaxed text-secondary-text"><strong>El Escenario:</strong><br>Imagina que eres un chef novato en un restaurante de alta cocina que usa una técnica innovadora para sus salsas. El chef principal no te da una lista de ingredientes ni pasos abstractos para la "Salsa Umami Perfecta", sino que te muestra tres ejemplos concretos:
                    <ol class="list-decimal list-inside ml-6 mt-2 space-y-1">
                        <li><strong>Ejemplo 1:</strong> Una pequeña cata de la "Salsa Umami para Pescado Blanco", con su textura, color y aroma.</li>
                        <li><strong>Ejemplo 2:</strong> Otra cata de la "Salsa Umami para Carne Roja", con diferencias sutiles pero claras.</li>
                        <li><strong>Ejemplo 3:</strong> Una tercera cata de la "Salsa Umami para Verduras Asadas", con otro perfil distintivo.</li>
                    </ol>
                    Luego, te pide que crees una "Salsa Umami para un Plato de Setas Silvestres", algo que nunca antes habías hecho.
                </p>
                <p class="mb-4 text-sm md:text-base leading-relaxed text-secondary-text"><strong>Análisis (El "Insight"):</strong></p>
                <ul class="list-disc list-inside text-secondary-text space-y-2 ml-4">
                    <li class="pl-2"><strong class="text-primary-text">¿Por qué funciona?:</strong> Al probar los tres ejemplos, tu cerebro de chef no solo memoriza los sabores, sino que <em>infiere los patrones subyacentes</em>: qué ingredientes o proporciones cambian para adaptarse a diferentes platos, cómo se ajusta la acidez o la dulzura. No necesitas una receta explícita de cada componente; los ejemplos te dan el conocimiento implícito para generalizar a la nueva tarea de las setas. Esto imita cómo los humanos aprenden de unos pocos ejemplos.</li>
                    <li class="pl-2"><strong class="text-primary-text">Aplicación:</strong> De manera similar, la técnica Few-Shot permite a un modelo de lenguaje grande (LLM) inferir patrones, estructura y el estilo de respuesta deseado a partir de unos pocos ejemplos concretos proporcionados directamente en el prompt. El modelo no se "reentrena" con cada ejemplo, sino que utiliza su conocimiento pre-entrenado para reconocer y aplicar las reglas implícitas de los ejemplos a la nueva solicitud.</li>
                </ul>
            </div>

            <!-- Example 2: Clasificador de Reseñas Instantáneo -->
            <div class="group bg-bg-subtle p-8 rounded-xl shadow-xl border border-border-subtle hover:shadow-2xl hover:border-accent-purple/50 hover:-translate-y-1 transition-all duration-300 ease-in-out mb-12 animate-fade-in-up" style="animation-delay: 1.8s;">
                <h3 class="font-display text-2xl text-primary-text mb-3">Clasificador de Reseñas Instantáneo</h3>
                <p class="text-sm text-secondary-text mb-4"><strong>Nivel:</strong> Técnico</p>
                <blockquote class="border-l-4 border-accent-gold pl-4 italic text-secondary-text mb-6 bg-bg-dark/50 py-3 rounded-r-md">
                    <strong class="text-primary-text">Concepto Clave:</strong> El LLM procesa el prompt completo, usando los ejemplos proporcionados para reconocer el patrón subyacente y el estilo de respuesta deseado.
                </blockquote>
                <p class="mb-4 text-sm md:text-base leading-relaxed text-secondary-text"><strong>El Escenario:</strong><br>Un estudiante de mercadotecnia necesita clasificar rápidamente una serie de reseñas de productos en línea, pero quiere que el sistema también identifique la emoción principal. Ha decidido usar un LLM y la técnica Few-Shot para lograrlo sin tener que entrenar un modelo desde cero. Su prompt se ve así:</p>
                <div class="overflow-x-auto bg-gray-100 border-4 border-slate-200 shadow-lg p-6 rounded-lg">
                    <pre><code class="language-prompt">Clasifica el siguiente texto de reseña indicando su sentimiento general (Positivo, Negativo, Neutro) y la emoción dominante (Alegría, Tristeza, Ira, Sorpresa, Miedo, Disgusto).

Ejemplo 1:
Texto: "La entrega fue sorprendentemente rápida y el producto superó mis expectativas. ¡Estoy muy contento!"
Clasificación: Sentimiento: Positivo, Emoción: Alegría

Ejemplo 2:
Texto: "El servicio al cliente fue pésimo y el artículo llegó dañado. Estoy furioso con la compra."
Clasificación: Sentimiento: Negativo, Emoción: Ira

Ejemplo 3:
Texto: "Funciona como se describe, nada extraordinario. Cumple su función."
Clasificación: Sentimiento: Neutro, Emoción: Ninguna

Ahora, clasifica el siguiente texto:
Texto: "Aunque el producto es bueno, el manual es confuso y pasé horas intentando configurarlo. ¡Qué frustración!"
Clasificación:
</code></pre>
                </div>
                <p class="my-4 text-sm md:text-base leading-relaxed text-secondary-text"><strong>Análisis (El "Insight"):</strong></p>
                <ul class="list-disc list-inside text-secondary-text space-y-2 ml-4">
                    <li class="pl-2"><strong class="text-primary-text">¿Por qué funciona?:</strong> El LLM recibe la instrucción general y, crucialmente, los tres pares de entrada-salida ("Texto: [Reseña]" y "Clasificación: [Sentimiento], Emoción: [Emoción]"). Al procesar estos ejemplos, el modelo identifica el <em>patrón</em> de clasificación deseado: cómo se extrae el sentimiento, cómo se mapea a una emoción específica y el formato exacto de salida. Cuando se le presenta el nuevo texto, el LLM no adivina; aplica el patrón y el formato que ha inferido de los ejemplos, generando una respuesta coherente como: "Sentimiento: Negativo, Emoción: Ira".</li>
                    <li class="pl-2"><strong class="text-primary-text">Aplicación:</strong> Esta técnica demuestra la eficiencia y flexibilidad del Few-Shot, permitiendo que el modelo comprenda y ejecute una tarea compleja (clasificación multietiqueta con formato específico) sin necesidad de ajustar sus parámetros internos. Es ideal para tareas que requieren una salida estructurada y consistente.</li>
                </ul>
            </div>

            <!-- Example 3: Auditoría de Cumplimiento Normativo en Finanzas -->
            <div class="group bg-bg-subtle p-8 rounded-xl shadow-xl border border-border-subtle hover:shadow-2xl hover:border-accent-purple/50 hover:-translate-y-1 transition-all duration-300 ease-in-out mb-12 animate-fade-in-up" style="animation-delay: 2s;">
                <h3 class="font-display text-2xl text-primary-text mb-3">Auditoría de Cumplimiento Normativo en Finanzas</h3>
                <p class="text-sm text-secondary-text mb-4"><strong>Nivel:</strong> Caso Real</p>
                <blockquote class="border-l-4 border-accent-gold pl-4 italic text-secondary-text mb-6 bg-bg-dark/50 py-3 rounded-r-md">
                    <strong class="text-primary-text">Concepto Clave:</strong> Few-shot prompting es particularmente útil para tareas complejas que involucran entradas variadas, requieren formato preciso o exigen un mayor grado de precisión.
                </blockquote>
                <p class="mb-4 text-sm md:text-base leading-relaxed text-secondary-text"><strong>El Escenario:</strong><br>Una firma de auditoría financiera necesita verificar rápidamente si los contratos de préstamo de un banco cumplen con una nueva regulación que exige la inclusión de cláusulas muy específicas sobre tasas de interés flotantes. Revisar manualmente miles de contratos es inviable. El equipo de IA de la firma decide implementar un sistema basado en LLMs utilizando Few-Shot Prompting. Crean un prompt donde:</p>
                <ol class="list-decimal list-inside space-y-2 ml-4 text-secondary-text">
                    <li class="pl-2"><strong class="text-primary-text">Instrucción inicial:</strong> Se le pide al LLM que analice extractos de contratos para identificar la presencia o ausencia de 3 cláusulas regulatorias clave y que genere un informe en formato JSON.</li>
                    <li class="pl-2"><strong class="text-primary-text">Ejemplos (entre 5 y 8):</strong> Se proporcionan extractos reales de contratos (entradas) con sus respectivas clasificaciones manuales (salidas en JSON), mostrando casos donde todas las cláusulas están presentes, donde falta alguna, donde el lenguaje es ambiguo, y cómo formatear la respuesta para cada escenario. Por ejemplo:
                        <div class="overflow-x-auto bg-gray-100 border-4 border-slate-200 shadow-lg p-6 rounded-lg">
                            <pre><code class="language-prompt"><em>Input:</em> &lt;code&gt;"...la tasa de interés variable se ajustará según Euríbor + 1.5% anual. La revisión trimestral es obligatoria y se notifica al cliente con 30 días de antelación. Cláusula de rescisión sin penalización tras 12 meses..."&lt;/code&gt;
<em>Output (JSON):</em> &lt;code&gt;{"Cláusula_Euríbor": "Presente", "Notificación_Cliente": "Presente", "Rescisión_Sin_Penalización": "Presente", "Cumplimiento_General": "Sí"}&lt;/code&gt;</code></pre>
                        </div>
                        <p class="mt-2 text-sm">Otro ejemplo mostraría un contrato no conforme y su JSON correspondiente.</p>
                    </li>
                    <li class="pl-2"><strong class="text-primary-text">Nueva entrada:</strong> El LLM recibe extractos de contratos nuevos y no auditados.</li>
                </ol>
                <p class="mb-4 text-sm md:text-base leading-relaxed text-secondary-text mt-4"><strong>Análisis (El "Insight"):</strong></p>
                <ul class="list-disc list-inside text-secondary-text space-y-2 ml-4">
                    <li class="pl-2"><strong class="text-primary-text">¿Por qué funciona?:</strong> La tarea es compleja debido a la variabilidad del lenguaje legal y la necesidad de una salida estructurada y precisa (JSON) que refleje la conformidad. Los ejemplos múltiples son cruciales porque el LLM no solo aprende a identificar las cláusulas, sino también a interpretar matices del lenguaje jurídico y, fundamentalmente, a <em>estructurar su respuesta en el formato JSON exigido</em>. Esto mejora significativamente la precisión en comparación con una instrucción simple (zero-shot) y permite que el modelo generalice de manera efectiva para auditar miles de contratos sin necesidad de costosas re-programaciones o fine-tuning.</li>
                    <li class="pl-2"><strong class="text-primary-text">Aplicación:</strong> En el mundo profesional, esta técnica se traduce en una eficiencia masiva, reduciendo drásticamente el tiempo y el costo de tareas de auditoría y cumplimiento. Permite a las empresas adaptarse rápidamente a nuevas regulaciones sin invertir en desarrollo de software prolongado, y garantiza un alto grado de consistencia y precisión en la identificación de elementos clave en documentos complejos.</li>
                </ul>
            </div>
        </article>
    </div>