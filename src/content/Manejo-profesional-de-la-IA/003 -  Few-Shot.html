
    <div class="relative overflow-hidden">
        <!-- Background decorative elements for dynamic aesthetic -->
        <div class="absolute top-0 left-0 w-80 h-80 bg-accent-purple rounded-full mix-blend-multiply filter blur-xl opacity-20 animate-spin-slow" style="animation-delay: -2s;"></div>
        <div class="absolute bottom-0 right-0 w-96 h-96 bg-accent-gold rounded-full mix-blend-multiply filter blur-xl opacity-20 animate-spin-slow"></div>

        <!-- Header -->
        <header class="relative pt-12 pb-16 text-center max-w-4xl mx-auto px-4 z-20">
            <div class="relative z-10 flex flex-col items-center">
                <!-- Title -->
                <h1 class="font-serif text-4xl md:text-6xl text-primary-dark mb-4 leading-tight tracking-tight animate-fade-in-up">
                    Aprendizaje por Ejemplos: Dominando la Técnica <em class="text-accent-gold not-italic">Few-Shot</em>
                </h1>
                <!-- Subtitle -->
                <div class="flex flex-col items-center gap-4 mt-4 animate-fade-in-up delay-200">
                    <span class="text-base font-serif text-secondary-light italic">Guía Profesional para la Interacción Efectiva con <em class="text-accent-gold not-italic">LLMs</em></span>
                    <div class="w-12 h-0.5 bg-gradient-to-r from-transparent via-accent-gold to-transparent rounded-full animate-grow-width"></div>
                </div>
            </div>
        </header>

        <article class="max-w-3xl mx-auto px-6 pb-20 z-20 relative">
            <!-- Introducción -->
            <p class="text-base md:text-lg leading-relaxed text-secondary-light text-center mb-16 animate-fade-in-up delay-400">
                Al finalizar este capítulo, el estudiante comprenderá y será capaz de aplicar la técnica <em class="text-accent-gold not-italic">Few-Shot Prompting</em> para guiar de manera efectiva a los <em class="text-accent-gold not-italic">LLM</em>, optimizando su rendimiento en tareas complejas sin reentrenamiento.
            </p>

            <!-- Image 1 -->
            <figure class="group w-full mb-16 relative rounded-xl overflow-hidden shadow-xl hover-lift animate-fade-in-up delay-600">
                <div class="bg-bg-subtle aspect-video md:aspect-[21/9] flex items-center justify-center overflow-hidden">
                    <img src="https://placehold.co/600x400?text=Introduccion+Few-Shot+Prompting" alt="Ilustración conceptual de la técnica Few-Shot Prompting, mostrando un modelo de lenguaje recibiendo instrucciones con ejemplos." class="h-full w-full object-cover object-center transform transition-transform duration-500 ease-out group-hover:scale-105">
                </div>
                <figcaption class="absolute bottom-0 left-0 right-0 bg-gradient-to-t from-bg-dark/80 to-transparent p-4 text-secondary-light text-xs text-right opacity-0 group-hover:opacity-100 transition-opacity duration-300">
                    Ilustración: <em class="text-accent-gold not-italic">Few-Shot Prompting</em>
                </figcaption>
            </figure>

            <!-- Body text container -->
            <div class="space-y-7 text-sm md:text-base leading-relaxed text-secondary-light mb-12">
                <p>
                    <strong class="text-primary-dark">Objetivo de Aprendizaje</strong><br>
                    Al finalizar este capítulo, el estudiante comprenderá y será capaz de aplicar la técnica <em class="text-accent-gold not-italic">Few-Shot Prompting</em> para guiar de manera efectiva a los <em class="text-accent-gold not-italic">Modelos de Lenguaje Grandes (LLM)</em>.
                </p>
                <p>
                    <strong class="text-primary-dark">Definición y Relevancia</strong><br>
                    La interacción con la inteligencia artificial generativa ha evolucionado rápidamente, pasando de instrucciones básicas a métodos más sofisticados que permiten una guía más precisa. Dentro de este panorama, emerge la <em class="text-accent-gold not-italic">técnica Few-Shot Prompting</em> como un pilar fundamental en el <em class="text-accent-gold not-italic">procesamiento del lenguaje natural (NLP)</em>. En esencia, esta técnica dota a un modelo de lenguaje con un reducido número de ejemplos de pares entrada-salida directamente dentro de la instrucción o <em class="text-accent-gold not-italic">prompt</em> que se le proporciona. Su relevancia radica en la capacidad de permitir que el modelo infiera patrones, estructuras y el formato de salida deseado para una nueva tarea no vista previamente, todo ello sin la exigencia de una extensa sintonización fina o un reentrenamiento completo.
                </p>
                <p>
                    <strong class="text-primary-dark">Antecedentes</strong><br>
                    Antes de la consolidación de técnicas como <em class="text-accent-gold not-italic">Few-Shot</em>, la interacción con los <em class="text-accent-gold not-italic">LLM</em> a menudo dependía del <em class="text-accent-gold not-italic">Zero-Shot Prompting</em>, donde el modelo debía ejecutar una tarea basándose únicamente en su conocimiento preentrenado y una descripción de la tarea, sin ejemplos. Si bien efectiva para tareas sencillas, las complejidades de ciertas aplicaciones demandaban una guía más explícita. La técnica <em class="text-accent-gold not-italic">Few-Shot</em> llena este vacío, aprovechando la vasta capacidad de los <em class="text-accent-gold not-italic">LLM</em> para generalizar a partir de información limitada, simulando un tipo de aprendizaje más cercano al humano.
                </p>
                <p>
                    Para comprender el <em class="text-accent-gold not-italic">Few-Shot Prompting</em>, imaginemos a un ser humano aprendiendo una nueva habilidad. Si le pedimos a alguien que clasifique diferentes tipos de frutas en "dulces" o "ácidas", y solo le decimos la regla, quizás cometa errores iniciales. Pero si le mostramos un par de ejemplos –"manzana: dulce", "limón: ácido", "plátano: dulce"–, la persona rápidamente aprenderá a identificar el patrón y aplicarlo a una nueva fruta como "naranja". Los <em class="text-accent-gold not-italic">Modelos de Lenguaje Grandes</em> operan de una manera análoga cuando se les aplica la técnica <em class="text-accent-gold not-italic">Few-Shot</em>.
                </p>
                <!-- Image 2 -->
                <figure class="group w-full mb-16 relative rounded-xl overflow-hidden shadow-xl hover-lift animate-fade-in-up delay-800">
                    <div class="bg-bg-subtle aspect-video md:aspect-[21/9] flex items-center justify-center overflow-hidden">
                        <img src="https://placehold.co/600x400?text=Analogia+Aprendizaje+Humano" alt="Ilustración comparando el aprendizaje humano con ejemplos y la técnica Few-Shot en LLMs." class="h-full w-full object-cover object-center transform transition-transform duration-500 ease-out group-hover:scale-105">
                    </div>
                    <figcaption class="absolute bottom-0 left-0 right-0 bg-gradient-to-t from-bg-dark/80 to-transparent p-4 text-secondary-light text-xs text-right opacity-0 group-hover:opacity-100 transition-opacity duration-300">
                        Ilustración: Analogía de Aprendizaje
                    </figcaption>
                </figure>
                <div class="border-l-4 border-accent-gold pl-6 py-4 bg-bg-subtle rounded-r-lg shadow-inner">
                    <p class="text-primary-dark italic text-lg">
                        <strong class="text-accent-gold">Insight Clave:</strong> El <em class="text-accent-gold not-italic">Few-Shot Prompting</em> no modifica los parámetros internos del modelo, sino que aprovecha su <em class="text-accent-gold not-italic">conocimiento preentrenado</em> para interpretar el contexto.
                    </p>
                </div>
                <p>
                    El proceso lógico detrás de la <em class="text-accent-gold not-italic">Few-Shot Prompting</em> se desglosa en varios pasos:
                </p>
                <!-- Ordered List -->
                <ol class="list-decimal list-inside space-y-3 pl-4 text-secondary-light">
                    <li class="pl-2"><strong class="text-primary-dark">Consulta del Usuario:</strong> Se formula una petición inicial al <em class="text-accent-gold not-italic">LLM</em>.</li>
                    <li class="pl-2"><strong class="text-primary-dark">Ejemplos en el Prompt:</strong> Varios ejemplos de la tarea deseada, presentados como pares de entrada y salida, se incluyen directamente en el <em class="text-accent-gold not-italic">prompt</em> junto con la nueva consulta. Típicamente, este número de ejemplos oscila entre 2 y 10, aunque puede variar según la complejidad de la tarea.</li>
                    <li class="pl-2"><strong class="text-primary-dark">Reconocimiento de Patrones:</strong> El <em class="text-accent-gold not-italic">LLM</em> procesa el <em class="text-accent-gold not-italic">prompt</em> en su totalidad. Utiliza los ejemplos para identificar el patrón subyacente, el contexto y el estilo de respuesta esperado. Es crucial entender que el modelo no está "aprendiendo" en el sentido tradicional de ajustar sus pesos, sino que está detectando la <em class="text-accent-gold not-italic">intención</em> y la <em class="text-accent-gold not-italic">estructura</em> implícita en la secuencia de ejemplos.</li>
                    <li class="pl-2"><strong class="text-primary-dark">Generación de Salida:</strong> Una vez que el patrón es reconocido, el modelo aplica esta comprensión para generar una salida para la nueva consulta que se alinea con los ejemplos proporcionados.</li>
                </ol>
                <p>
                    Esta mecánica ofrece ventajas significativas. Primero, una notable <em class="text-accent-gold not-italic">eficiencia y flexibilidad</em>, ya que reduce drásticamente la necesidad de grandes conjuntos de datos etiquetados y entrenamientos extensos. Esto permite capitalizar rápidamente los modelos preentrenados. Segundo, una <em class="text-accent-gold not-italic">mejora en la precisión</em>; al ofrecer múltiples ejemplos, el modelo adquiere una comprensión más profunda de tareas complejas, resultando en una mayor exactitud y consistencia en comparación con métodos <em class="text-accent-gold not-italic">Zero-Shot</em> o <em class="text-accent-gold not-italic">One-Shot</em>. Finalmente, su <em class="text-accent-gold not-italic">versatilidad</em> es inmensa, siendo aplicable a una vasta gama de tareas como la clasificación, la sumarización o la generación de resultados estructurados, sin necesidad de reentrenamiento para cada nueva tarea.
                </p>

                <!-- Section Title 2 -->
                <h3 class="font-serif text-3xl text-primary-dark mb-4 mt-12 pt-8 border-t border-accent-gold/20">Técnicas Avanzadas y Aplicación</h3>
                <p>
                    La implementación de la <em class="text-accent-gold not-italic">Few-Shot Prompting</em> profundiza en la capacidad de los <em class="text-accent-gold not-italic">LLM</em> para imitar el aprendizaje humano a partir de la experiencia. Bajo el capó, el "porqué" funciona reside en la arquitectura masiva de los <em class="text-accent-gold not-italic">transformadores</em> que sustentan a los <em class="text-accent-gold not-italic">LLM</em>, los cuales han sido preentrenados con cantidades ingentes de texto. Esta fase de preentrenamiento les confiere una capacidad intrínseca para identificar relaciones semánticas y sintácticas complejas. El "cómo" se ejecuta es a través de la cuidadosa selección e inclusión de los ejemplos en el <em class="text-accent-gold not-italic">prompt</em>, que actúan como "pistas contextuales" que dirigen la atención del modelo hacia el subconjunto de su vasto conocimiento más relevante para la tarea en cuestión.
                </p>
                <!-- Image 3 -->
                <figure class="group w-full mb-16 relative rounded-xl overflow-hidden shadow-xl hover-lift animate-fade-in-up delay-1000">
                    <div class="bg-bg-subtle aspect-video md:aspect-[21/9] flex items-center justify-center overflow-hidden">
                        <img src="https://placehold.co/600x400?text=Arquitectura+Transformer+LLM" alt="Diagrama simplificado de la arquitectura Transformer de un LLM." class="h-full w-full object-cover object-center transform transition-transform duration-500 ease-out group-hover:scale-105">
                    </div>
                    <figcaption class="absolute bottom-0 left-0 right-0 bg-gradient-to-t from-bg-dark/80 to-transparent p-4 text-secondary-light text-xs text-right opacity-0 group-hover:opacity-100 transition-opacity duration-300">
                        Ilustración: Arquitectura <em class="text-accent-gold not-italic">LLM</em>
                    </figcaption>
                </figure>
                <p>
                    A pesar de sus bondades, la técnica <em class="text-accent-gold not-italic">Few-Shot</em> no está exenta de limitaciones. Una de las más críticas es el <em class="text-accent-gold not-italic">tamaño de la ventana de contexto</em> del modelo, que determina la cantidad de texto que el <em class="text-accent-gold not-italic">LLM</em> puede procesar en una sola interacción. Esto limita directamente el número de ejemplos que pueden ser incluidos en el <em class="text-accent-gold not-italic">prompt</em>. Otra consideración fundamental es la <em class="text-accent-gold not-italic">selección de ejemplos</em>: la calidad y la pertinencia de los ejemplos proporcionados son cruciales, ya que ejemplos mal elegidos pueden llevar a un rendimiento subóptimo del modelo. Además, existe un <em class="text-accent-gold not-italic">potencial de sesgo</em>: cualquier sesgo inherente en los ejemplos puede ser aprendido y, por consiguiente, propagado por el modelo en sus respuestas.
                </p>
                <p>
                    Para situar la <em class="text-accent-gold not-italic">Few-Shot Prompting</em> en perspectiva, es útil compararla con otras técnicas:
                </p>
                <ul class="list-disc list-inside text-secondary-light space-y-3 pl-4">
                    <li class="pl-2"><strong class="text-primary-dark">Zero-Shot Prompting:</strong> El modelo recibe solo una descripción de la tarea, sin ejemplos. Confía enteramente en su conocimiento preentrenado. Es óptima para tareas rápidas donde el modelo debería entender la solicitud sin guía adicional.</li>
                    <li class="pl-2"><strong class="text-primary-dark">One-Shot Prompting:</strong> Se proporciona un único ejemplo para aclarar la tarea o el formato deseado. Es útil cuando se necesita una guía más específica que <em class="text-accent-gold not-italic">Zero-Shot</em>, o cuando el modelo puede lidiar con ambigüedad.</li>
                    <li class="pl-2">La <em class="text-accent-gold not-italic">Few-Shot Prompting</em> se posiciona como un punto intermedio potente, ofreciendo más guía que las anteriores para una comprensión más robusta.</li>
                </ul>

                <h3 class="font-serif text-3xl text-primary-dark mb-4 mt-12 pt-8 border-t border-accent-gold/20">Escenarios de Aplicación</h3>
                <p>
                    La utilidad de la <em class="text-accent-gold not-italic">Few-Shot Prompting</em> se manifiesta especialmente en tareas complejas que demandan una variedad de entradas, requieren un formato preciso o exigen un alto grado de precisión.
                </p>
                <p>
                    <strong class="text-primary-dark">Análisis de Sentimiento:</strong> Los modelos pueden clasificar el sentimiento de un texto (positivo, negativo, neutro) con datos etiquetados limitados, si se les proporcionan unos pocos ejemplos de cómo se han clasificado previamente textos similares. Por ejemplo, <code class="bg-bg-subtle px-1 rounded text-accent-gold">Input: "Excelente servicio." -> Output: Positivo. Input: "Retraso inaceptable." -> Output: Negativo. Input: "El producto llegó." -> Output: Neutro.</code>
                </p>
                <p>
                    <strong class="text-primary-dark">Reconocimiento de Acciones en Videos:</strong> Aunque la investigación base no profundiza, esta aplicación sugiere cómo el modelo podría aprender a identificar patrones de comportamiento a partir de un puñado de descripciones o transcripciones de acciones específicas.
                </p>
                <p>
                    <strong class="text-primary-dark">Generación de Salida Estructurada:</strong> Para extraer información específica o reformatear datos, los ejemplos pueden mostrar al <em class="text-accent-gold not-italic">LLM</em> exactamente cómo se espera la salida (ej., convertir texto libre en formato JSON).
                </p>

                <h3 class="font-serif text-3xl text-primary-dark mb-4 mt-12 pt-8 border-t border-accent-gold/20">Técnicas Avanzadas Adicionales</h3>
                <p>
                    La <em class="text-accent-gold not-italic">Few-Shot Prompting</em> puede combinarse y complementarse con otras estrategias para potenciar aún más la interacción con los <em class="text-accent-gold not-italic">LLM</em>:
                </p>
                <ul class="list-disc list-inside text-secondary-light space-y-3 pl-4">
                    <li class="pl-2"><strong class="text-primary-dark">Chain-of-Thought (CoT) Prompting:</strong> Esta técnica anima al modelo a generar pasos de razonamiento intermedios antes de ofrecer la respuesta final. Al integrar <em class="text-accent-gold not-italic">CoT</em> con <em class="text-accent-gold not-italic">Few-Shot</em>, los ejemplos no solo muestran la entrada y la salida, sino también el <em class="text-accent-gold not-italic">proceso de pensamiento</em> que lleva a esa salida, mejorando la coherencia y la lógica del resultado.</li>
                    <li class="pl-2"><strong class="text-primary-dark">Ejecución de Tareas Multi-Paso:</strong> Para tareas que inherentemente requieren múltiples etapas, dividir el <em class="text-accent-gold not-italic">prompt</em> en partes más pequeñas y manejables, cada una con sus propios ejemplos <em class="text-accent-gold not-italic">Few-Shot</em>, puede ser muy efectivo.</li>
                    <li class="pl-2"><strong class="text-primary-dark">Juego de Roles y Comprensión Contextual:</strong> Proporcionar al modelo un rol específico (ej., "Eres un experto en <em class="text-accent-gold not-italic">marketing</em>") o una información contextual más profunda puede refinar aún más su producción, guiándolo a adoptar un estilo o una perspectiva particular, incluso en los ejemplos <em class="text-accent-gold not-italic">Few-Shot</em>.</li>
                </ul>

                <!-- Important Text Callout -->
                <div class="my-16 text-center animate-fade-in-up delay-700">
                    <p class="font-serif text-xl md:text-3xl text-primary-dark leading-normal mb-4 border-l-4 border-accent-gold pl-6 py-4 bg-bg-subtle rounded-r-lg shadow-inner italic">
                       La <em class="text-accent-gold not-italic">Few-Shot Prompting</em> representa un paradigma de cómo podemos enseñar a las máquinas a generalizar a partir de la experiencia, emulando la cognición humana.
                    </p>
                </div>

                <div class="h-0.5 bg-gradient-to-r from-transparent via-border-subtle to-transparent rounded-full my-12"></div>
            </div>
        </article>

        <article class="max-w-3xl mx-auto px-6 pb-20 z-20 relative">
            <h2 class="font-serif text-4xl text-primary-dark mb-8 mt-20 text-center animate-fade-in-up delay-1400">Ejemplos Prácticos</h2>

            <!-- Example 1: La Receta del Chef Aprendiz -->
            <div class="group bg-bg-subtle p-8 rounded-xl shadow-xl border border-accent-gold/20 hover-lift mb-12 animate-fade-in-up delay-1600">
                <h3 class="font-serif text-2xl text-primary-dark mb-3">La Receta del Chef Aprendiz</h3>
                <p class="text-sm text-secondary-light mb-4"><strong class="text-primary-dark">Nivel:</strong> Analogía</p>
                <blockquote class="border-l-4 border-accent-gold pl-4 italic text-secondary-light mb-6 bg-bg-subtle py-3 rounded-r-md">
                    <strong class="text-accent-gold">Concepto Clave:</strong> Proporcionar un pequeño número de ejemplos de entrada-salida para guiar al modelo en tareas nuevas.
                </blockquote>
                <p class="mb-4 text-sm md:text-base leading-relaxed text-secondary-light"><strong class="text-primary-dark">El Escenario:</strong><br>Imagina que eres un chef novato en un restaurante de alta cocina que usa una técnica innovadora para sus salsas. El chef principal no te da una lista de ingredientes ni pasos abstractos para la "Salsa Umami Perfecta", sino que te muestra tres ejemplos concretos:
                    <ol class="list-decimal list-inside ml-6 mt-2 space-y-1">
                        <li><strong class="text-primary-dark">Ejemplo 1:</strong> Una pequeña cata de la "Salsa Umami para Pescado Blanco", con su textura, color y aroma.</li>
                        <li><strong class="text-primary-dark">Ejemplo 2:</strong> Otra cata de la "Salsa Umami para Carne Roja", con diferencias sutiles pero claras.</li>
                        <li><strong class="text-primary-dark">Ejemplo 3:</strong> Una tercera cata de la "Salsa Umami para Verduras Asadas", con otro perfil distintivo.</li>
                    </ol>
                    Luego, te pide que crees una "Salsa Umami para un Plato de Setas Silvestres", algo que nunca antes habías hecho.
                </p>
                <p class="mb-4 text-sm md:text-base leading-relaxed text-secondary-light"><strong class="text-primary-dark">Análisis (El "Insight"):</strong></p>
                <ul class="list-disc list-inside text-secondary-light space-y-2 ml-4">
                    <li class="pl-2"><strong class="text-primary-dark">¿Por qué funciona?:</strong> Al probar los tres ejemplos, tu cerebro de chef no solo memoriza los sabores, sino que <em class="text-accent-gold not-italic">infiere los patrones subyacentes</em>: qué ingredientes o proporciones cambian para adaptarse a diferentes platos, cómo se ajusta la acidez o la dulzura. No necesitas una receta explícita de cada componente; los ejemplos te dan el conocimiento implícito para generalizar a la nueva tarea de las setas. Esto imita cómo los humanos aprenden de unos pocos ejemplos.</li>
                    <li class="pl-2"><strong class="text-primary-dark">Aplicación:</strong> De manera similar, la técnica <em class="text-accent-gold not-italic">Few-Shot</em> permite a un <em class="text-accent-gold not-italic">modelo de lenguaje grande (LLM)</em> inferir patrones, estructura y el estilo de respuesta deseado a partir de unos pocos ejemplos concretos proporcionados directamente en el <em class="text-accent-gold not-italic">prompt</em>. El modelo no se "reentrena" con cada ejemplo, sino que utiliza su conocimiento pre-entrenado para reconocer y aplicar las reglas implícitas de los ejemplos a la nueva solicitud.</li>
                </ul>
            </div>

            <!-- Example 2: Clasificador de Reseñas Instantáneo -->
            <div class="group bg-bg-subtle p-8 rounded-xl shadow-xl border border-accent-gold/20 hover-lift mb-12 animate-fade-in-up delay-1800">
                <h3 class="font-serif text-2xl text-primary-dark mb-3">Clasificador de Reseñas Instantáneo</h3>
                <p class="text-sm text-secondary-light mb-4"><strong class="text-primary-dark">Nivel:</strong> Técnico</p>
                <blockquote class="border-l-4 border-accent-gold pl-4 italic text-secondary-light mb-6 bg-bg-subtle py-3 rounded-r-md">
                    <strong class="text-accent-gold">Concepto Clave:</strong> El <em class="text-accent-gold not-italic">LLM</em> procesa el <em class="text-accent-gold not-italic">prompt</em> completo, usando los ejemplos proporcionados para reconocer el patrón subyacente y el estilo de respuesta deseado.
                </blockquote>
                <p class="mb-4 text-sm md:text-base leading-relaxed text-secondary-light"><strong class="text-primary-dark">El Escenario:</strong><br>Un estudiante de mercadotecnia necesita clasificar rápidamente una serie de reseñas de productos en línea, pero quiere que el sistema también identifique la emoción principal. Ha decidido usar un <em class="text-accent-gold not-italic">LLM</em> y la técnica <em class="text-accent-gold not-italic">Few-Shot</em> para lograrlo sin tener que entrenar un modelo desde cero. Su <em class="text-accent-gold not-italic">prompt</em> se ve así:</p>
                <div class="overflow-x-auto bg-bg-subtle border border-accent-gold/20 shadow-lg p-6 rounded-lg">
                    <pre><code class="language-xml text-secondary-light font-mono whitespace-pre-wrap">Clasifica el siguiente texto:
 
Ejemplo 1:
Texto: "La entrega fue excelente. ¡Estoy muy contento!"
Clasificación: Sentimiento: Positivo, Emoción: Alegría
 
Ejemplo 2:
Texto: "El artículo llegó dañado. Estoy furioso."
Clasificación: Sentimiento: Negativo, Emoción: Ira
 
Nueva Entrada: "El manual es confuso. ¡Qué frustración!"
Clasificación:</code></pre>
                </div>
                <p class="my-4 text-sm md:text-base leading-relaxed text-secondary-light"><strong class="text-primary-dark">Análisis (El "Insight"):</strong></p>
                <ul class="list-disc list-inside text-secondary-light space-y-2 ml-4">
                    <li class="pl-2"><strong class="text-primary-dark">¿Por qué funciona?:</strong> El <em class="text-accent-gold not-italic">LLM</em> recibe la instrucción general y, crucialmente, los tres pares de entrada-salida ("Texto: [Reseña]" y "Clasificación: [Sentimiento], Emoción: [Emoción]"). Al procesar estos ejemplos, el modelo identifica el <em class="text-accent-gold not-italic">patrón</em> de clasificación deseado: cómo se extrae el sentimiento, cómo se mapea a una emoción específica y el formato exacto de salida. Cuando se le presenta el nuevo texto, el <em class="text-accent-gold not-italic">LLM</em> no adivina; aplica el patrón y el formato que ha inferido de los ejemplos, generando una respuesta coherente como: "Sentimiento: Negativo, Emoción: Ira".</li>
                    <li class="pl-2"><strong class="text-primary-dark">Aplicación:</strong> Esta técnica demuestra la eficiencia y flexibilidad del <em class="text-accent-gold not-italic">Few-Shot</em>, permitiendo que el modelo comprenda y ejecute una tarea compleja (clasificación multietiqueta con formato específico) sin necesidad de ajustar sus parámetros internos. Es ideal para tareas que requieren una salida estructurada y consistente.</li>
                </ul>
            </div>

            <!-- Example 3: Auditoría de Cumplimiento Normativo en Finanzas -->
            <div class="group bg-bg-subtle p-8 rounded-xl shadow-xl border border-border-subtle hover:shadow-2xl hover:border-accent-purple/50 hover:-translate-y-1 transition-all duration-300 ease-in-out mb-12 animate-fade-in-up" style="animation-delay: 2s;">
                <h3 class="font-display text-2xl text-primary-text mb-3">Auditoría de Cumplimiento Normativo en Finanzas</h3>
                <p class="text-sm text-secondary-text mb-4"><strong>Nivel:</strong> Caso Real</p>
                <blockquote class="border-l-4 border-accent-gold pl-4 italic text-secondary-text mb-6 bg-bg-dark/50 py-3 rounded-r-md">
                    <strong class="text-primary-text">Concepto Clave:</strong> Few-shot prompting es particularmente útil para tareas complejas que involucran entradas variadas, requieren formato preciso o exigen un mayor grado de precisión.
                </blockquote>
                <p class="mb-4 text-sm md:text-base leading-relaxed text-secondary-text"><strong>El Escenario:</strong><br>Una firma de auditoría financiera necesita verificar rápidamente si los contratos de préstamo de un banco cumplen con una nueva regulación que exige la inclusión de cláusulas muy específicas sobre tasas de interés flotantes. Revisar manualmente miles de contratos es inviable. El equipo de IA de la firma decide implementar un sistema basado en LLMs utilizando Few-Shot Prompting. Crean un prompt donde:</p>
                <ol class="list-decimal list-inside space-y-2 ml-4 text-secondary-text">
                    <li class="pl-2"><strong class="text-primary-text">Instrucción inicial:</strong> Se le pide al LLM que analice extractos de contratos para identificar la presencia o ausencia de 3 cláusulas regulatorias clave y que genere un informe en formato JSON.</li>
                    <li class="pl-2"><strong class="text-primary-text">Ejemplos (entre 5 y 8):</strong> Se proporcionan extractos reales de contratos (entradas) con sus respectivas clasificaciones manuales (salidas en JSON), mostrando casos donde todas las cláusulas están presentes, donde falta alguna, donde el lenguaje es ambiguo, y cómo formatear la respuesta para cada escenario. Por ejemplo:
                        <div class="overflow-x-auto bg-gray-100 border-4 border-slate-200 shadow-lg p-6 rounded-lg">
                            <pre><code class="language-xml text-secondary-light font-mono whitespace-pre-wrap"><em>Input:</em> &lt;code&gt;"...la tasa de interés variable se ajustará según Euríbor + 1.5% anual. La revisión trimestral es obligatoria y se notifica al cliente con 30 días de antelación. Cláusula de rescisión sin penalización tras 12 meses..."&lt;/code&gt;
<em>Output (JSON):</em> &lt;code&gt;{"Cláusula_Euríbor": "Presente", "Notificación_Cliente": "Presente", "Rescisión_Sin_Penalización": "Presente", "Cumplimiento_General": "Sí"}&lt;/code&gt;</code></pre>
                        </div>
                        <p class="mt-2 text-sm">Otro ejemplo mostraría un contrato no conforme y su JSON correspondiente.</p>
                    </li>
                    <li class="pl-2"><strong class="text-primary-text">Nueva entrada:</strong> El LLM recibe extractos de contratos nuevos y no auditados.</li>
                </ol>
                <p class="mb-4 text-sm md:text-base leading-relaxed text-secondary-text mt-4"><strong>Análisis (El "Insight"):</strong></p>
                <ul class="list-disc list-inside text-secondary-text space-y-2 ml-4">
                    <li class="pl-2"><strong class="text-primary-text">¿Por qué funciona?:</strong> La tarea es compleja debido a la variabilidad del lenguaje legal y la necesidad de una salida estructurada y precisa (JSON) que refleje la conformidad. Los ejemplos múltiples son cruciales porque el LLM no solo aprende a identificar las cláusulas, sino también a interpretar matices del lenguaje jurídico y, fundamentalmente, a <em>estructurar su respuesta en el formato JSON exigido</em>. Esto mejora significativamente la precisión en comparación con una instrucción simple (zero-shot) y permite que el modelo generalice de manera efectiva para auditar miles de contratos sin necesidad de costosas re-programaciones o fine-tuning.</li>
                    <li class="pl-2"><strong class="text-primary-text">Aplicación:</strong> En el mundo profesional, esta técnica se traduce en una eficiencia masiva, reduciendo drásticamente el tiempo y el costo de tareas de auditoría y cumplimiento. Permite a las empresas adaptarse rápidamente a nuevas regulaciones sin invertir en desarrollo de software prolongado, y garantiza un alto grado de consistencia y precisión en la identificación de elementos clave en documentos complejos.</li>
                </ul>
            </div>
        </article>
    </div>